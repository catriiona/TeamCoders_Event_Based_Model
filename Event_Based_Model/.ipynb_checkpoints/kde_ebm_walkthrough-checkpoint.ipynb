{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Course Sequencing with the EBM\n",
    "## Event-Based Model of disease progression\n",
    "Author: Neil Oxtoby, UCL (with some slight modifications for TeamCoders from Dave Cash)\n",
    "\n",
    "Originally a tutorial on the [DPM website](https://disease-progression-modelling.github.io) and current notebook originally taken from the [KDE-EBM Github repository](https://github.com/ucl-pond/kde_ebm)\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "This demonstration notebook walks you through how to fit an event-based model of disease progression using publicly available software and simulated data. After going through this notebook, you should have tkhe knowledge to set up the EBM for your data in the project notebook.\n",
    "\n",
    "The steps for perorming an EBM analysis typically involve:\n",
    "- Load input data, usually in some tabular format, that contains the disease features (biomarkers) you wish to include in an EBM, from a cohort that includes both patients and healthy controls\n",
    "- Prepare the input data: select a subset of features; perform some basic statistical checks; etc.\n",
    "- Fit the model\n",
    "- Perform cross-validation\n",
    "\n",
    "We add additional steps as didactic exemplars of good practice in data-driven disease progression modelling. \n",
    "\n",
    "## The set-up\n",
    "\n",
    "This notebook is currently designed to run in a clean conda environment that you shoud have installed as part of the setup for this Team Coders project. For further information about how to instal the [KDE EBM](https://github.com/ucl-pond/kde_ebm) package (see [installation instructions](https://github.com/ucl-pond/kde_ebm/blob/master/INSTALL.md) on GitHub).\n",
    "\n",
    "We will start the notebook by importing some key packages needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18}) # default fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating simulated data\n",
    "The data we are going to use for this walkthrough are simulated, to provide a controlled example of what the EBM should provide you. In this simulation, we will create 100 patients, each with complete case data consisting of four different biomarkers or features that will be used as an event, and 100 controls, who all should have roughly normal values. In all of these biomarker values, a value of 0 represents a normal value, and 1 represents a very abnormal value.\n",
    "\n",
    "### Patients\n",
    "In most data sets, we do not know how long the patient has had the disease for. In this simulation, we assume that we know exactly how long it has been since the onset of the disease, and the 100 patients are equally spaced along this disease duration from 0 (onset of disease) to twenty years after onset. Each of the four biomarkers switch from normal to abnormal at different phases of the disease. This transition follows a sigmoidal relationship, with some noise built in. The simulated data can be represented as a two-dimensional matrix, with 100 rows (the number of patients) by four columns (the number of features). We call this matrix `X_patients` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 4   # number of events/features\n",
    "num_patients = 100 # number of patients\n",
    "disease_duration = 20 # Number of years \n",
    "\n",
    "noise_scale = 0.1\n",
    "\n",
    "# Define the disease progression timeline: from 0 (right at onset of disease)\n",
    "# to 20 (20 years past the onset of disease)\n",
    "# We will be generating subjects equally spaced along this disease progression timeline\n",
    "disease_time = np.linspace(0, disease_duration, num_patients)\n",
    "\n",
    "# Helpful function to geneate sigmoid biomarker trajectories along the disease time\n",
    "sigmoid = lambda t, a=1, b=-10 : 1/(1 + np.exp(-a*(t-b)))\n",
    "\n",
    "X_patients = np.empty(shape=(num_patients,num_features))\n",
    "\n",
    "# If using dark background, then keep the next line in, otherwise comment it out.\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Get the colors of the plot so points and lines can be the same. \n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "# List of dictionaries for key plotting information of each biomarker\n",
    "feature_info = [\n",
    "    { 'label': 'Biomarker 1', 'gradient': 1, 'onset': 4, 'color': colors[0]},\n",
    "    { 'label': 'Biomarker 2', 'gradient': 1, 'onset': 8, 'color': colors[1]},\n",
    "    { 'label': 'Biomarker 3', 'gradient': 1, 'onset': 12, 'color': colors[2]},\n",
    "    { 'label': 'Biomarker 4', 'gradient': 1, 'onset': 16, 'color': colors[3]}\n",
    "]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "k=0\n",
    "for feature in feature_info:\n",
    "    # print('a = %i, b = %i' % (a,b))\n",
    "    x = sigmoid(t=disease_time,a=feature['gradient'],b=feature['onset'])\n",
    "    #print(x)\n",
    "    ax.plot(disease_time, x, c = feature['color'])\n",
    "    y = x + np.random.normal(0, noise_scale, x.size)\n",
    "    X_patients[:,k] = y\n",
    "    ax.plot(disease_time, y,'.',label=feature['label'], c = feature['color'])\n",
    "    k = k + 1\n",
    "\n",
    "ax.set_xlabel(\"Disease Progression Time\",fontsize=20) \n",
    "ax.set_ylabel(\"Biomarker Value\",fontsize=20)\n",
    "ax.legend(bbox_to_anchor=(1.02, 0.5),loc=\"center left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function ensures that all of these features turn abnormal at different times `feature['onset']` so that more individuals have biomarker 1 turning abnormal then 2,3,4.\n",
    "\n",
    "### Control data\n",
    "We also need to simulate some controls. For these simulated subjects, we will assume that none will have abnormal values, just some random noise around zero. We will store this matrix of observations in `X_controls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Sample some controls\n",
    "X_controls = np.empty(shape=X_patients.shape)\n",
    "for k in range(num_features):\n",
    "    X_controls[:,k] = np.random.normal(0, 0.05, (X_controls.shape[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the simulated data\n",
    "\n",
    "### Visual inspection of feature distributions\n",
    "\n",
    "The first question we should ask when thinking about whether to include a feature in the Event Based Model is \"does the feature relate to the disease process?\" There is no sense in putting a feature in the EBM if there is no difference in feature's value between patients and controls. The first step is to just *look at the data* by visually checking the feature's distribution in our patient group and control group to make sure there is some evidence of separation between groups. In the plots below, you can see that for each biomarker the controls stay densely packed around the zero value while the patients have a larger spread. The spread is larger in the earlier biomarkers where less individuals remain within normal levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* 1. Histograms\n",
    "fig,ax = plt.subplots(num_features,1,figsize=(8,14))\n",
    "for k in range(num_features):\n",
    "    ax[k].hist([ X_patients[:,k],X_controls[:,k]],label=['Patients','Controls'])\n",
    "    ax[k].set_title('Biomarker %i' % (k+1),fontsize=16)\n",
    "ax[0].legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistical tests\n",
    "\n",
    "We can more formally assess a feature's ability to discriminate between patients and controls using statistical tests. Here we will use non-parametric tests, which make no assumptions about the underlying distribution of the features, where the null hypothesis is that there are no \"differences\" between groups. If the p-value of such a statistical test is sufficiently low, this is interpreted as sufficient evidence to reject the null hypothesis, i.e., this suggests the presence of some \"disease signal\" in a biomarker (patient measurements are \"different\" to controls measurements) and thus this feature might have potential as a feature in the EBM.\n",
    "\n",
    "Details about the statistical test used below:\n",
    "- Mann-Whitney U test (quoting Wikipedia):<br/>\n",
    "> a nonparametric test of the null hypothesis that, for randomly selected values X and Y from two populations, the probability of X being greater than Y is equal to the probability of Y being greater than X.\n",
    "- Effect size: (difference in medians) / (\"width\" of controls distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* 2. Basic statistics\n",
    "# I use a nonparametric test because it works regardless of the data distributions \n",
    "# (some tests assume some level of Gaussianity)\n",
    "from scipy import stats\n",
    "print('Mann Whitney U test')\n",
    "\n",
    "for k in range(num_features):\n",
    "    x_c = X_controls[:,k]\n",
    "    x_p = X_patients[:,k]\n",
    "    effect_size = np.absolute(np.median(x_p)-np.median(x_c))/stats.median_abs_deviation(x_c)\n",
    "    u,p = stats.mannwhitneyu(x_c,x_p)\n",
    "    print('Biomarker %i\\n - effect size = %.3g\\n - u = %i, p = %.2g' % (k+1,effect_size,u,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All four statistical tests show substantial evidence of a difference between patients and controls, so they can all be included in the EBM. As expected, the biomarkers that become abnormal earliest in the disease process (1 and 2) have more abnormal values and thus the effect size is the largest (and the p-value is the smallest, as would be expected) in these biomarkers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for fitting\n",
    "Now that we have determined which features are appropriate for the model, we need to organise the data in a structure that is ready for use in the EBM package. This includes combining all of the patient group and controls into one matrix. We need to add a *label* to tell the EBM which individuals are patients and which individuals are controls. These are stored in the variables `y_patients` and `y_controls`. `X_combined` and `Y_combined` hold these two matrices stacked vertically into one longer matrix, with the patients in the first 100 rows and the controls in the next 100 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Setup data for fitting\n",
    "y_patients = np.ones(shape=(X_patients.shape[0],1))\n",
    "y_controls = np.zeros(shape=(X_controls.shape[0],1))\n",
    "\n",
    "X_combined = np.concatenate((X_patients,X_controls),axis=0)\n",
    "Y_combined = np.concatenate((y_patients,y_controls),axis=0)\n",
    "# Make sure that these labels are stored as integer format.\n",
    "Y_combined = Y_combined.flatten().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit mixture models\n",
    "\n",
    "We now need to map each of the biomarker values to its corresponding probability given that the \"event\" has occurred, denoted as `p(data|event)`, which represents how abnormal the biomarker value is. A key point here is that the EBM is a probabilistic framework. There is no magic cutpoint where individuals instantly turn from normal to abnormal, but rather the probability that the measured biomarker is abnormal,  allowing for patients to be at different stages of cumulative abnormality.\n",
    "\n",
    "Typical group-level analyses simply compare measurements from patients with controls, e.g., looking for statistical \"differences\" in the mean values. The mixture model allows for patients to have both abnormal observations that deviate from controls (these are early disease events), and normal observations (these will be later disease events that have not yet occurred in these patients.)\n",
    "\n",
    "The first step is to import all the eleements of the kde_ebm package that are needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kde_ebm.mixture_model import fit_all_kde_models\n",
    "\n",
    "from kde_ebm.plotting import mixture_model_grid, mcmc_uncert_mat, mcmc_trace, stage_histogram\n",
    "\n",
    "from kde_ebm.mcmc import mcmc, parallel_bootstrap, bootstrap_ebm, bootstrap_ebm_fixedMM, bootstrap_ebm_return_mixtures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of visualisation, we are creating a few helpful labels for the biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Label the biomarkers/events\n",
    "event_labels = ['Early','Early-ish','Late-ish','Late']\n",
    "#* Direction of progression (1 = biomarker increases in patients; -1 = biomarker decreases in patients)\n",
    "#  This is a feature of the KDE EBM software.\n",
    "event_disease_direction_dict = {'Early':1,'Early-ish':1,'Late-ish':1,'Late':1}\n",
    "event_disease_direction = [event_disease_direction_dict[f] for f in event_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the mixture models for each of these biomarkers. In some of the original papers this was done with a Gaussian mixture model, where the underlying distribution of both patients and controls were assumed to have Gaussian distributions. The KDE does not make that assumption and thus can handle data with different distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_mixtures = fit_all_kde_models(\n",
    "    X_combined, Y_combined,\n",
    "    implement_fixed_controls = True,\n",
    "    patholog_dirn_array      = event_disease_direction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next command allows us to view the mixture models that were fit to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* View the mixture models\n",
    "mixture_model_grid(\n",
    "    X_combined,Y_combined,\n",
    "    kde_mixtures,\n",
    "    score_names=event_labels,\n",
    "    class_names=['Controls','Patients']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that despite these events all having different distributions, since they become abnormal at different points of the disease process, the plot of `p(data|event)` looks roughly the same for each biomarker, turning abnormal at roughly the same levels (0.25 to 0.50), because we have defined the range of normal measurements from healthy controls on similar scales across all features. Note that the number of patients who have a value classified as abnormal is different for each biomarker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing using MCMC: Markov Chain Monte Carlo\n",
    "\n",
    "We want to extract the model posterior, which will provide the point estimate of the most probable ordering of events, given the data. Ideally, we could calculate the likelihood of every single possible ordering combination and the ordering with the maximum likelihood would be our result. However for $N$ features, this results in $N!$ possible orderings. For our case of four orderings, this would be feasible as it results in $4!$ or 24 possible orderings. However as the number of events included increases, the number of possible orderings explodes. For example, doubling the number of events in the model to eight, results in 40,320 possible orderings. This is where the Markov Chain Monte Carlo method comes into play, it is a standard method for approximating a model posterior when exact inference is intractable.\n",
    "\n",
    "With MCMC, we generate _random samples from the posterior_ (the full set of possible sequences), and keep only those sequences that increase the likelihood (ideally towards the maximum).\n",
    "\n",
    "In practice, the posterior won't be a convex function, i.e., one having a single easy-to-find maximum. The posterior could consist of multiple local maxima at different locations in parameter space. To avoid getting \"stuck\" in a local maximum, we follow good machine learning practice when searching parameter space to sample from the posterior: multiple random initialisations of the sampling, greedy initialisation, and MCMC sampling.\n",
    "\n",
    "Details of the bespoke MCMC algorithm used here are in the original EBM paper: [Fonteijn _et al._, NeuroImage (2012)](https://doi.org/10.1016/j.neuroimage.2012.01.062).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Perform MCMC sequencing and store results in mcmc_samples\n",
    "mcmc_samples = mcmc(X_combined, kde_mixtures)\n",
    "#* Obtaine the maximum Likelihood sequence over all samples\n",
    "seq_ml = mcmc_samples[0].ordering\n",
    "# print('ML sequence: {0}'.format(seq_ml))\n",
    "print('ML order   : %s' % ', '.join([event_labels[k] for k in seq_ml]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the ML posterior\n",
    "f,a = mcmc_uncert_mat(mcmc_samples, ml_order=None, score_names=event_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ordering is as we would expect it to be, the Early one is first, followed by Early-ish, Late-ish, and Late. This corresponds with how these biomarkers were set to transition from normal to abnormal at 4, 8, 12, and 16 years, respectively. \n",
    "\n",
    "We are going to use the results from the MCMC sampling later, so we are going to save them in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in a dict()\n",
    "ebm_results = {\"mixtures\": kde_mixtures, \"mcmc_samples\": mcmc_samples, \"sequence_ml\": seq_ml}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Variance Diagrams — estimating order uncertainty\n",
    "\n",
    "The EBM posterior is the best estimate of the most likely ordering and its uncertainty. However, it is based on a single sample of data. If we had a different sample of the population, which might be more heterogeneous or have more noise in the measurements, then we might get a different result. The concept of the _positional variance diagram_, or PVD, can illustrate this. Here the ordering is shown not as one dark box at the specific order, but rather smeared out across the possible orderings determined by the MCMC sampling.\n",
    "\n",
    "In the file `kde_utils.py`, there are some convenience functions defined to help with some of the next few cells. If interested in what they do, please look at them. If you want to use them in your notebook, please use the import kde_utils command below. The first two functions used in the cell below are:\n",
    "* `extract_pvd`: this extracts the positional variance diagram \n",
    "* `save_plot`: Saves a plot of the PVD for use in publications and talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kde_utils \n",
    "nom = 'tute'\n",
    "#* Plot EBM (PVD)\n",
    "pvd_ml, seq_ml = kde_utils.extract_pvd(ml_order=seq_ml,samples=mcmc_samples)\n",
    "reorder_ml = np.argsort(seq_ml)\n",
    "pvd_ml_ = pvd_ml[:][reorder_ml]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(9, 6),sharey=False)\n",
    "labels = event_labels\n",
    "labels_ = [labels[i].replace('TOTAL','').replace('TOT','').replace('-detrended','') for i in seq_ml]\n",
    "ax.imshow(pvd_ml_[:][seq_ml], interpolation='nearest', cmap='Reds')\n",
    "\n",
    "n_biomarkers = pvd_ml.shape[0]\n",
    "stp = 1\n",
    "fs = 14\n",
    "tick_marks_x = np.arange(0,n_biomarkers,stp)\n",
    "x_labs = range(1, n_biomarkers+1,stp)\n",
    "ax.set_xticks(tick_marks_x)\n",
    "ax.set_xticklabels(x_labs, rotation=0,fontsize=fs)\n",
    "tick_marks_y = np.arange(n_biomarkers)\n",
    "ax.set_yticks(tick_marks_y+0.0)\n",
    "ax.tick_params(axis='y',color='w')\n",
    "labels_trimmed = [x[2:].replace('_', ' ') if x.startswith('p_') else x.replace('_', ' ') for x in labels_]\n",
    "ax.set_yticklabels(labels_trimmed,#,np.array(labels_trimmed, dtype='object')[seq_],\n",
    "                   rotation=0, #ha='right',\n",
    "                   rotation_mode='anchor',\n",
    "                   fontsize=18)\n",
    "# ax.set_ylabel('Instrument', fontsize=28)\n",
    "ax.set_xlabel('Positional Variance', fontsize=24)\n",
    "ax.grid(False)\n",
    "\n",
    "kde_utils.save_plot(fig, nom+\"-PVD_ML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient staging utility\n",
    "\n",
    "Now that we have an event based model describing the ordering (and its uncertainty) across our population, we can use the model to identify at which point, or stage, each individual is within the disease process. \n",
    "\n",
    "The staging method (see [Young et al, Brain 2014](https://doi.org/10.1093/brain/awu176)) compares data from each individual (patients/controls/at-risk) with the model and calculates a `p(event)` vector. From this vector, the most likely stage according to the accumulation of disease events can be assigned for each individual. This can even be used for followup timepoints, or from individuals that aren't included in the trained model to show the amount of progression that occurs within individuals over time. \n",
    "\n",
    "The actual staging function is stored in `kde_utils.py` and is called `ebm_staging`. It creates four outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Staging\n",
    "#* Maximum-likelihood model stage: could include longitudinal data, including followups not used to train the EBM\n",
    "prob_mat_ml, stages_long_ml, stage_likelihoods_long_ml, stages_long_ml_expected = kde_utils.ebm_staging(\n",
    "    x=X_combined,\n",
    "    mixtures=kde_mixtures,\n",
    "    samples=mcmc_samples\n",
    ")\n",
    "stages_long = stages_long_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained stages for each individual, we will plot a histogram of the stages assigned to each individual (both controls and patients). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.hist([ stages_long[Y_combined==0], stages_long[Y_combined==1]],bins=np.arange(-0.5,num_features+1.5,1))\n",
    "ax.set_ylabel('Number of individuals',fontsize=20)\n",
    "ax.legend(['Controls','Patients'],fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the controls are in stage 0, i.e., they don't have any evidence of the disease, and our patient group is more or less split across each of the potential disease stages, some not showing any signs of the disease yet with others showing abnormal values (\"events\") in all biomarkers. \n",
    "\n",
    "To illustrate how individuals match up with the stages from the EBM, let's plot each of the four bioarkers for each individual with respect to disease time. **This time** we will colour each individual's points according to their disease stage. As expected, individuals who have progressed the furthest in the disease are at the most severe stage, while those who are have just recently had onset are in stage 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Plot the original data, coloured by stage\n",
    "fig,ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "for k in range(num_features):\n",
    "    scatter = plt.scatter(disease_time,X_combined[Y_combined==1,k],c=stages_long[Y_combined==1],cmap='viridis',label='')\n",
    "#ax.legend(['Stage %i' % k for k in range(num_stages)],loc='center right',bbox_to_anchor=[1.5,0.5])\n",
    "# produce a legend with the unique colors from the scatter\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"upper left\", title=\"Stages\")\n",
    "ax.add_artist(legend1)\n",
    "ax.set_xlabel(\"Disease Progression Time\",fontsize=20) \n",
    "ax.set_ylabel(\"Biomarker Value\",fontsize=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<hr/>\n",
    "\n",
    "## Bonus: Cross-validation\n",
    "\n",
    "Generalizability/robustness of a model can be quantified by **testing** the model on independent data, i.e., data not included when training the model.\n",
    "\n",
    "Cross-validation does this by splitting the available data into train/test sets.\n",
    "\n",
    "### k-fold cross-validation\n",
    "\n",
    "Splitting a dataset into `k` \"folds\" enables calculation of model performance statistics (e.g., mean, standard deviation) over `k` test sets, using the other `k-1` folds to train the model each time.\n",
    "\n",
    "It is common to use `k=10`, which amounts to using 90% of your data to train and 10% to test.\n",
    "\n",
    "This process can be repeated multiple times using different random partitions (splits) into folds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_kfold_cv](https://upload.wikimedia.org/wikipedia/commons/b/b5/K-fold_cross_validation_EN.svg)\n",
    "\n",
    "By Gufosowa - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=82298768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `k=5` folds and repeat the k-fold CV process for 10 random splits.\n",
    "\n",
    "The next cell uses the function `ebm_2_repeatedcv` in `kde_utils.py` to assist with the cross-validation of the EBM. It fits the EBM 50 times — for each of the 10 replications, the model is run `k=5` times, allowing each one of the folds to be held out for testing while the other four folds are used to fit the EBM.\n",
    "\n",
    "**Caveat** at the moment, the output of this cell is quite verbose, with lots of plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#* RCV1: Repeated, stratified 5-fold CV - uses ML stage as ground truth for test folds\n",
    "k_folds = 5\n",
    "n_repeats = 10\n",
    "\n",
    "#Sets up the random folds to be used in cross-validation. This just states which folds\n",
    "#each individual belongs to.\n",
    "repeated_cvfolds = RepeatedStratifiedKFold(n_splits=k_folds, n_repeats=n_repeats) #, random_state=36851234)\n",
    "\n",
    "# Have we already run the EBM?\n",
    "if 'ebm_results' in locals():\n",
    "    check = True\n",
    "else:\n",
    "    check = False\n",
    "\n",
    "#And if we have, have we already run the cross-validation? We can save some time\n",
    "#if we already have. Otherwise, we will need to run it.\n",
    "if check:\n",
    "    if \"mixtures_rcv\" in ebm_results:\n",
    "        kde_mixtures_rcv = ebm_results[\"mixtures_rcv\"]\n",
    "        mcmc_samples_rcv = ebm_results[\"mcmc_samples_rcv\"]\n",
    "        seqs_rcv = ebm_results[\"sequences_rcv\"]\n",
    "        staging_errors_rcv = ebm_results[\"staging_errors_rcv\"]\n",
    "        runit = False\n",
    "    else:\n",
    "        runit = True\n",
    "else:\n",
    "    runit = True\n",
    "\n",
    "if runit:\n",
    "    kde_mixtures_rcv, mcmc_samples_rcv, seqs_rcv, staging_errors_rcv = kde_utils.ebm_2_repeatedcv(\n",
    "        x=X_combined,\n",
    "        y=Y_combined,\n",
    "        events=event_labels,\n",
    "        rcv_folds=repeated_cvfolds,\n",
    "        implement_fixed_controls=True,\n",
    "        patholog_dirn_array=event_disease_direction,\n",
    "        model_stage=stages_long\n",
    "    )\n",
    "    #* Save\n",
    "    ebm_results[\"mixtures_rcv\"] = kde_mixtures_rcv\n",
    "    ebm_results[\"mcmc_samples_rcv\"] = mcmc_samples_rcv\n",
    "    ebm_results[\"sequences_rcv\"] = seqs_rcv\n",
    "    ebm_results[\"staging_errors_rcv\"] = staging_errors_rcv\n",
    "    # pickle_file = open(pickle_path,'wb')\n",
    "    # pickle_output = pickle.dump(ebm_results, pickle_file)\n",
    "    # pickle_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have multiple orderings from each of the cross-validation results. The helper function `extract_pvd` can handle this scenario too and provide an ordering that combines the orderings all together. This is especially useful on real data, but given how tight the ordering is in our simulated data, there is no change to the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Plot EBM (PVD)\n",
    "pvd_rcv, seq_rcv = kde_utils.extract_pvd(ml_order=seqs_rcv,samples=mcmc_samples_rcv)\n",
    "reorder_rcv = np.argsort(seq_rcv)\n",
    "pvd_rcv_ = pvd_rcv[:][reorder_rcv]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(9, 6),sharey=False)\n",
    "labels = event_labels\n",
    "labels_ = [labels[i].replace('TOTAL','').replace('TOT','').replace('-detrended','') for i in seq_rcv]\n",
    "ax.imshow(pvd_rcv_[:][seq_rcv], interpolation='nearest', cmap='Oranges')\n",
    "# ax.set_title('Cross-Validation',fontsize=24)\n",
    "\n",
    "n_biomarkers = pvd_rcv.shape[0]\n",
    "stp = 1\n",
    "fs = 14\n",
    "tick_marks_x = np.arange(0,n_biomarkers,stp)\n",
    "x_labs = range(1, n_biomarkers+1,stp)\n",
    "ax.set_xticks(tick_marks_x)\n",
    "ax.set_xticklabels(x_labs, rotation=0,fontsize=fs)\n",
    "tick_marks_y = np.arange(n_biomarkers)\n",
    "ax.set_yticks(tick_marks_y+0)\n",
    "ax.tick_params(axis='y',color='w')\n",
    "labels_trimmed = [x[2:].replace('_', ' ') if x.startswith('p_') else x.replace('_', ' ') for x in labels_]\n",
    "ax.set_yticklabels(labels_trimmed,#,np.array(labels_trimmed, dtype='object')[seq_],\n",
    "                   rotation=0, #ha='right',\n",
    "                   rotation_mode='anchor',\n",
    "                   fontsize=18)\n",
    "# ax.set_ylabel('Instrument', fontsize=28)\n",
    "ax.set_xlabel('Sequence', fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running on real data, you might consider staging your participant data using the cross-validated model (above uses the maximum-likelihood model which can be over-confident). Then you might re-run the CV.\n",
    "\n",
    "Another thing to consider after this clean example is to make the data dirtier. Slow down the gradient of the sigmoid, add some noise, or bunch up the orderings to see how this affects EBM uncertainty and the PVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ca3c52c2c6a741687ac119195f853fd55cbbadb57e664fb666b72dd14734ec5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('teamcoder_ebm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
