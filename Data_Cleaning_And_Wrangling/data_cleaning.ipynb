{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling and Visualization workbook\n",
    "This workbook will be used to generate the data file that will be ready for use in the Event Based Model. Along the way, you will need to implement some of the data cleaning, data wrangling and data visualization skills that you learned in the demonstration notebook using the WHO cases data.  In the project notebook below, you will find instructions for what to do in each step followed by an empty code cell to enter your work. Don't forget that you will need to import the appropriate packages for this work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your import steps here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Load in ADNIMERGE\n",
    "The first step we must do is to identify the measurements that will be used as features in the Event Based Model. From [Alex Young's original paper](https://academic.oup.com/brain/article/137/9/2564/2848155), the features that are to be included are: \n",
    "* Cerebrospinal Fluid (CSF) INNO-BIA AlzBio3 immunoassay ('INNO')\n",
    "  * Amyloid Beta 1-42\n",
    "  * phosphorylated tau\n",
    "  * total tau\n",
    "* Volumetric measurements from **1.5T** magnetic resonance imaging (MRI)\n",
    "  * Whole brain volume\n",
    "  * Ventricular volume\n",
    "  * Entorhinal cortex volume\n",
    "  * Hippocampal volume\n",
    "  * Middle temporal cortex volume\n",
    "  * Fusiform cortex volume \n",
    "  * Annualised whole brain atrophy between 0 and **12 months** using Boundary Shift Integral (BSI)\n",
    "  * Annualised hippocampal atrophy between 0 and **12 months** using Boundary Shift Integral (BSI)\n",
    "* Cognitive measures\n",
    "  * Mini mental state examination (MMSE)\n",
    "  * ADAS-COG13\n",
    "  * Rey Auditory Verbal Learning Test (RAVLT)\n",
    "\n",
    "Many of these features should be available in the ADNI MERGE dataset. The file is donwloaded from Teams and is called `adnimerge_ideas_merge_26may2022.csv`. We have included both the data dictionary and the methods so that you can better understand how this spreadsheet was created and what it represents. Please load in the ADNIMERGE spreadsheet. \n",
    "Here are some of the questions:\n",
    "* Which column identifies the subject?\n",
    "* Can you identify the features above in the column? \n",
    "* Are any of the features above missing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 117  TAU_INNO                  float64\n",
    "#  118  ABETA_INNO                float64\n",
    "#  119  PTAU_INNO                 float64\n",
    " \n",
    "#   55   WholeBrain                float64\n",
    "#  53   Ventricles                float64\n",
    "#   56   Entorhinal                float64\n",
    "#  54   Hippocampus               float64\n",
    "#   58   MidTemp                   float64\n",
    "#  57   Fusiform                  float64\n",
    "#  5   ANN_BBSI    8421 non-null   float64       \n",
    "#  10  ANN_HBSI    4661 non-null   float64       \n",
    "\n",
    "# 26   MMSE                      float64\n",
    "#  24   ADAS13                    float64\n",
    "\n",
    "#  27   RAVLT_immediate           float64\n",
    "#  28   RAVLT_learning            float64\n",
    "#  29   RAVLT_forgetting          float64\n",
    "#  30   RAVLT_perc_forgetting     float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catriona/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (20,105,116) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Your answer to Step 1\n",
    "# Below put your code that will load up the ADNI MERGE spreadsheet\n",
    "input_file = \"data/adnimerge_ideas_merge_26may2022.csv\" \n",
    "df_raw = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15856 entries, 0 to 15855\n",
      "Data columns (total 120 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   RID                       int64  \n",
      " 1   COLPROT                   object \n",
      " 2   ORIGPROT                  object \n",
      " 3   PTID                      object \n",
      " 4   SITE                      int64  \n",
      " 5   VISCODE                   object \n",
      " 6   EXAMDATE                  object \n",
      " 7   DX_bl                     object \n",
      " 8   AGE                       float64\n",
      " 9   PTGENDER                  object \n",
      " 10  PTEDUCAT                  int64  \n",
      " 11  PTETHCAT                  object \n",
      " 12  PTRACCAT                  object \n",
      " 13  PTMARRY                   object \n",
      " 14  APOE4                     float64\n",
      " 15  FDG                       float64\n",
      " 16  PIB                       float64\n",
      " 17  AV45                      float64\n",
      " 18  FBB                       float64\n",
      " 19  ABETA_ELECSYS             object \n",
      " 20  TAU_ELECSYS               object \n",
      " 21  PTAU_ELECSYS              object \n",
      " 22  CDRSB                     float64\n",
      " 23  ADAS11                    float64\n",
      " 24  ADAS13                    float64\n",
      " 25  ADASQ4                    float64\n",
      " 26  MMSE                      float64\n",
      " 27  RAVLT_immediate           float64\n",
      " 28  RAVLT_learning            float64\n",
      " 29  RAVLT_forgetting          float64\n",
      " 30  RAVLT_perc_forgetting     float64\n",
      " 31  LDELTOTAL                 float64\n",
      " 32  DIGITSCOR                 float64\n",
      " 33  TRABSCOR                  float64\n",
      " 34  FAQ                       float64\n",
      " 35  MOCA                      float64\n",
      " 36  EcogPtMem                 float64\n",
      " 37  EcogPtLang                float64\n",
      " 38  EcogPtVisspat             float64\n",
      " 39  EcogPtPlan                float64\n",
      " 40  EcogPtOrgan               float64\n",
      " 41  EcogPtDivatt              float64\n",
      " 42  EcogPtTotal               float64\n",
      " 43  EcogSPMem                 float64\n",
      " 44  EcogSPLang                float64\n",
      " 45  EcogSPVisspat             float64\n",
      " 46  EcogSPPlan                float64\n",
      " 47  EcogSPOrgan               float64\n",
      " 48  EcogSPDivatt              float64\n",
      " 49  EcogSPTotal               float64\n",
      " 50  FLDSTRENG                 object \n",
      " 51  FSVERSION                 object \n",
      " 52  IMAGEUID                  float64\n",
      " 53  Ventricles                float64\n",
      " 54  Hippocampus               float64\n",
      " 55  WholeBrain                float64\n",
      " 56  Entorhinal                float64\n",
      " 57  Fusiform                  float64\n",
      " 58  MidTemp                   float64\n",
      " 59  ICV                       float64\n",
      " 60  DX                        object \n",
      " 61  mPACCdigit                float64\n",
      " 62  mPACCtrailsB              float64\n",
      " 63  EXAMDATE_bl               object \n",
      " 64  CDRSB_bl                  float64\n",
      " 65  ADAS11_bl                 float64\n",
      " 66  ADAS13_bl                 float64\n",
      " 67  ADASQ4_bl                 float64\n",
      " 68  MMSE_bl                   float64\n",
      " 69  RAVLT_immediate_bl        float64\n",
      " 70  RAVLT_learning_bl         float64\n",
      " 71  RAVLT_forgetting_bl       float64\n",
      " 72  RAVLT_perc_forgetting_bl  float64\n",
      " 73  LDELTOTAL_BL              float64\n",
      " 74  DIGITSCOR_bl              float64\n",
      " 75  TRABSCOR_bl               float64\n",
      " 76  FAQ_bl                    float64\n",
      " 77  mPACCdigit_bl             float64\n",
      " 78  mPACCtrailsB_bl           float64\n",
      " 79  FLDSTRENG_bl              object \n",
      " 80  FSVERSION_bl              object \n",
      " 81  IMAGEUID_bl               float64\n",
      " 82  Ventricles_bl             float64\n",
      " 83  Hippocampus_bl            float64\n",
      " 84  WholeBrain_bl             float64\n",
      " 85  Entorhinal_bl             float64\n",
      " 86  Fusiform_bl               float64\n",
      " 87  MidTemp_bl                float64\n",
      " 88  ICV_bl                    float64\n",
      " 89  MOCA_bl                   float64\n",
      " 90  EcogPtMem_bl              float64\n",
      " 91  EcogPtLang_bl             float64\n",
      " 92  EcogPtVisspat_bl          float64\n",
      " 93  EcogPtPlan_bl             float64\n",
      " 94  EcogPtOrgan_bl            float64\n",
      " 95  EcogPtDivatt_bl           float64\n",
      " 96  EcogPtTotal_bl            float64\n",
      " 97  EcogSPMem_bl              float64\n",
      " 98  EcogSPLang_bl             float64\n",
      " 99  EcogSPVisspat_bl          float64\n",
      " 100 EcogSPPlan_bl             float64\n",
      " 101 EcogSPOrgan_bl            float64\n",
      " 102 EcogSPDivatt_bl           float64\n",
      " 103 EcogSPTotal_bl            float64\n",
      " 104 ABETA_bl                  object \n",
      " 105 TAU_bl                    object \n",
      " 106 PTAU_bl                   object \n",
      " 107 FDG_bl                    float64\n",
      " 108 PIB_bl                    float64\n",
      " 109 AV45_bl                   float64\n",
      " 110 FBB_bl                    float64\n",
      " 111 Years_bl                  float64\n",
      " 112 Month_bl                  float64\n",
      " 113 Month                     int64  \n",
      " 114 M                         int64  \n",
      " 115 update_stamp              object \n",
      " 116 TEMPQC                    object \n",
      " 117 TAU_INNO                  float64\n",
      " 118 ABETA_INNO                float64\n",
      " 119 PTAU_INNO                 float64\n",
      "dtypes: float64(91), int64(5), object(24)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Filter data\n",
    "The event based model primarily works on cross-sectional data. In the data, the features you have identified from ADNIMERGE should be coming from the **baseline** visit and from scans acquired on a **1.5T** scanner.  Figure out how to filter the rows according to these two criteria. The resulting data frame should have 818 rows remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 818 entries, 0 to 7234\n",
      "Columns: 120 entries, RID to PTAU_INNO\n",
      "dtypes: float64(91), int64(5), object(24)\n",
      "memory usage: 773.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your answer to Step 2\n",
    "# Below put your code that will filter the ADNI MERGE spreadsheet\n",
    "\n",
    "# for column in df_raw:  \n",
    "#     print(column)\n",
    "#     print(df_raw[column].value_counts())\n",
    "#     print('----')\n",
    "\n",
    "fld = df_raw['FLDSTRENG'] #want 1.5T values only\n",
    "vsc = df_raw['VISCODE'] #want bl values only\n",
    "\n",
    "fld.unique() #array(['1.5 Tesla MRI', nan, '3 Tesla MRI'], dtype=object)\n",
    "vsc.isna().value_counts() #no null values in vsc, so can separate out these rows already\n",
    "fld.isna().value_counts() #9935 null values in fld so need to work on this\n",
    "\n",
    "#remove NaN rows from fld\n",
    "df_complete = df_raw.dropna(axis=0, subset=['FLDSTRENG'])\n",
    "fld = df_complete['FLDSTRENG'] #want 1.5T values onlycr\n",
    "fld.value_counts()\n",
    "\n",
    "#group by vsc, select 'bl' then group by fld, select '1.5 Tesla MRI' only\n",
    "df_by_vsc= df_complete.groupby(['VISCODE'])\n",
    "df_bl=df_by_vsc.get_group('bl')\n",
    "df_bl_fld= df_bl.groupby(['FLDSTRENG'])\n",
    "df_bl_fld_opf=df_bl_fld.get_group('1.5 Tesla MRI')\n",
    "\n",
    "#get info to check 818 rows\n",
    "df_bl_fld_opf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_bl_fld_opf.info(max)\n",
    "# df_bl_fld_opf['RID'].unique()\n",
    "# df_bl_fld_opf['EXAMDATE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Merging data\n",
    "You should have identified that some features from the original list that are missing in the ADNI MERGE spreadsheet. There is another spreadsheet in the data folder called `ucl_bsi_ideas_merge_26may2022.csv` where you will find the additional data.\n",
    "\n",
    "In order to combine data you need to *merge* the two data sets. This involves finding key identifiers (the \"on\" columns) that will correspond to the same subject in both spreadsheets, so that the columns can be combined together in one data frame. Please remember that we only need BSI values from 0 to 12 months, so think about what filtering you will need to do with the new spreadsheet that you are loading in before performing the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer to Step 3\n",
    "# Below put your code that will merge the ADNI MERGE spreadsheet\n",
    "# with other ADNI data availale.\n",
    "\n",
    "new_input_file = \"data/ucl_bsi_ideas_merge_26may2022.csv\" \n",
    "df_new_raw = pd.read_csv(new_input_file)\n",
    "\n",
    "# df_new_raw.info()\n",
    "# df_bl_fld_opf.info(max)\n",
    "\n",
    "#create new dataframes as copies of original ones\n",
    "df_new_date = df_new_raw.copy()\n",
    "df_old_date = df_bl_fld_opf.copy()\n",
    "\n",
    "df_new_date['EXAMDATE'] = pd.to_datetime(df_new_raw['EXAMDATE'])\n",
    "df_old_date['EXAMDATE'] = pd.to_datetime(df_bl_fld_opf['EXAMDATE'])\n",
    "\n",
    "#remove unnecessary columns\n",
    "selected_columns = ['RID', 'VISCODE', 'VISCODE2', 'EXAMDATE', 'ANN_BBSI', 'ANN_HBSI', 'MRFIELD', 'MRSEQUENCE', 'PROTOCOL', 'QC_PASS', 'REGRATING']\n",
    "df_new_date_clean = df_new_date.loc[:, selected_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13875 entries, 0 to 13874\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   RID         13875 non-null  int64         \n",
      " 1   VISCODE     13875 non-null  object        \n",
      " 2   VISCODE2    13875 non-null  object        \n",
      " 3   EXAMDATE    13875 non-null  datetime64[ns]\n",
      " 4   ANN_BBSI    8421 non-null   float64       \n",
      " 5   ANN_HBSI    4661 non-null   float64       \n",
      " 6   MRFIELD     13875 non-null  float64       \n",
      " 7   MRSEQUENCE  13875 non-null  object        \n",
      " 8   PROTOCOL    13875 non-null  object        \n",
      " 9   QC_PASS     13875 non-null  int64         \n",
      " 10  REGRATING   9320 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_new_raw.head(50)\n",
    "df_new_date_clean.info(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#extract only the 1.5T scans\n",
    "df_new_date_clean['MRFIELD'].value_counts()\n",
    "df_new_clean_mri = df_new_date_clean[df_new_date_clean['MRFIELD'] == 1.5]\n",
    "# df_new_clean_mri.info(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_new_raw.sort_values('RID') #need to merge using RID as this is the patient ID I believe\n",
    "# df_new_raw['VISCODE2'].value_counts()\n",
    "\n",
    "# #There are only a couple of those values so will delete them, including only sc, scmri, m06, m12, bl\n",
    "df_new_vsc = df_new_clean_mri.groupby(['VISCODE2'])\n",
    "# df_new_vsc_bl = df_new_vsc.get_group('bl')\n",
    "# df_new_vsc_sc = df_new_vsc.get_group('sc')\n",
    "# df_new_vsc_m06 = df_new_vsc.get_group('m06')\n",
    "df_new_vsc_m12 = df_new_vsc.get_group('m12')\n",
    "\n",
    "#combine relevant scans back into single dataframe and sort by RID\n",
    "df_new_firstyear = pd.concat([df_new_vsc_m12]) #df_new_vsc_bl, df_new_vsc_sc, df_new_vsc_m06, \n",
    "df_new_firstyear = df_new_firstyear.sort_values('RID')\n",
    "\n",
    "#outer merge of both dataframes by RID (which is the common date format column)\n",
    "df_bothdata = pd.merge(df_new_firstyear, df_old_date,\n",
    "                        how='outer',on=['RID'],\n",
    "                        suffixes=['_old','_new'],indicator=True).sort_values('RID')\n",
    "\n",
    "# df_bothdata.info(max)\n",
    "df_bothdata['_merge'].value_counts()\n",
    "df_bothdata = df_bothdata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 818 entries, 0 to 817\n",
      "Data columns (total 131 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   RID                       int64         \n",
      " 1   VISCODE_old               object        \n",
      " 2   VISCODE2                  object        \n",
      " 3   EXAMDATE_old              datetime64[ns]\n",
      " 4   ANN_BBSI                  float64       \n",
      " 5   ANN_HBSI                  float64       \n",
      " 6   MRFIELD                   float64       \n",
      " 7   MRSEQUENCE                object        \n",
      " 8   PROTOCOL                  object        \n",
      " 9   QC_PASS                   float64       \n",
      " 10  REGRATING                 float64       \n",
      " 11  COLPROT                   object        \n",
      " 12  ORIGPROT                  object        \n",
      " 13  PTID                      object        \n",
      " 14  SITE                      int64         \n",
      " 15  VISCODE_new               object        \n",
      " 16  EXAMDATE_new              datetime64[ns]\n",
      " 17  DX_bl                     object        \n",
      " 18  AGE                       float64       \n",
      " 19  PTGENDER                  object        \n",
      " 20  PTEDUCAT                  int64         \n",
      " 21  PTETHCAT                  object        \n",
      " 22  PTRACCAT                  object        \n",
      " 23  PTMARRY                   object        \n",
      " 24  APOE4                     float64       \n",
      " 25  FDG                       float64       \n",
      " 26  PIB                       float64       \n",
      " 27  AV45                      float64       \n",
      " 28  FBB                       float64       \n",
      " 29  ABETA_ELECSYS             object        \n",
      " 30  TAU_ELECSYS               object        \n",
      " 31  PTAU_ELECSYS              object        \n",
      " 32  CDRSB                     float64       \n",
      " 33  ADAS11                    float64       \n",
      " 34  ADAS13                    float64       \n",
      " 35  ADASQ4                    float64       \n",
      " 36  MMSE                      float64       \n",
      " 37  RAVLT_immediate           float64       \n",
      " 38  RAVLT_learning            float64       \n",
      " 39  RAVLT_forgetting          float64       \n",
      " 40  RAVLT_perc_forgetting     float64       \n",
      " 41  LDELTOTAL                 float64       \n",
      " 42  DIGITSCOR                 float64       \n",
      " 43  TRABSCOR                  float64       \n",
      " 44  FAQ                       float64       \n",
      " 45  MOCA                      float64       \n",
      " 46  EcogPtMem                 float64       \n",
      " 47  EcogPtLang                float64       \n",
      " 48  EcogPtVisspat             float64       \n",
      " 49  EcogPtPlan                float64       \n",
      " 50  EcogPtOrgan               float64       \n",
      " 51  EcogPtDivatt              float64       \n",
      " 52  EcogPtTotal               float64       \n",
      " 53  EcogSPMem                 float64       \n",
      " 54  EcogSPLang                float64       \n",
      " 55  EcogSPVisspat             float64       \n",
      " 56  EcogSPPlan                float64       \n",
      " 57  EcogSPOrgan               float64       \n",
      " 58  EcogSPDivatt              float64       \n",
      " 59  EcogSPTotal               float64       \n",
      " 60  FLDSTRENG                 object        \n",
      " 61  FSVERSION                 object        \n",
      " 62  IMAGEUID                  float64       \n",
      " 63  Ventricles                float64       \n",
      " 64  Hippocampus               float64       \n",
      " 65  WholeBrain                float64       \n",
      " 66  Entorhinal                float64       \n",
      " 67  Fusiform                  float64       \n",
      " 68  MidTemp                   float64       \n",
      " 69  ICV                       float64       \n",
      " 70  DX                        object        \n",
      " 71  mPACCdigit                float64       \n",
      " 72  mPACCtrailsB              float64       \n",
      " 73  EXAMDATE_bl               object        \n",
      " 74  CDRSB_bl                  float64       \n",
      " 75  ADAS11_bl                 float64       \n",
      " 76  ADAS13_bl                 float64       \n",
      " 77  ADASQ4_bl                 float64       \n",
      " 78  MMSE_bl                   float64       \n",
      " 79  RAVLT_immediate_bl        float64       \n",
      " 80  RAVLT_learning_bl         float64       \n",
      " 81  RAVLT_forgetting_bl       float64       \n",
      " 82  RAVLT_perc_forgetting_bl  float64       \n",
      " 83  LDELTOTAL_BL              float64       \n",
      " 84  DIGITSCOR_bl              float64       \n",
      " 85  TRABSCOR_bl               float64       \n",
      " 86  FAQ_bl                    float64       \n",
      " 87  mPACCdigit_bl             float64       \n",
      " 88  mPACCtrailsB_bl           float64       \n",
      " 89  FLDSTRENG_bl              object        \n",
      " 90  FSVERSION_bl              object        \n",
      " 91  IMAGEUID_bl               float64       \n",
      " 92  Ventricles_bl             float64       \n",
      " 93  Hippocampus_bl            float64       \n",
      " 94  WholeBrain_bl             float64       \n",
      " 95  Entorhinal_bl             float64       \n",
      " 96  Fusiform_bl               float64       \n",
      " 97  MidTemp_bl                float64       \n",
      " 98  ICV_bl                    float64       \n",
      " 99  MOCA_bl                   float64       \n",
      " 100 EcogPtMem_bl              float64       \n",
      " 101 EcogPtLang_bl             float64       \n",
      " 102 EcogPtVisspat_bl          float64       \n",
      " 103 EcogPtPlan_bl             float64       \n",
      " 104 EcogPtOrgan_bl            float64       \n",
      " 105 EcogPtDivatt_bl           float64       \n",
      " 106 EcogPtTotal_bl            float64       \n",
      " 107 EcogSPMem_bl              float64       \n",
      " 108 EcogSPLang_bl             float64       \n",
      " 109 EcogSPVisspat_bl          float64       \n",
      " 110 EcogSPPlan_bl             float64       \n",
      " 111 EcogSPOrgan_bl            float64       \n",
      " 112 EcogSPDivatt_bl           float64       \n",
      " 113 EcogSPTotal_bl            float64       \n",
      " 114 ABETA_bl                  object        \n",
      " 115 TAU_bl                    object        \n",
      " 116 PTAU_bl                   object        \n",
      " 117 FDG_bl                    float64       \n",
      " 118 PIB_bl                    float64       \n",
      " 119 AV45_bl                   float64       \n",
      " 120 FBB_bl                    float64       \n",
      " 121 Years_bl                  float64       \n",
      " 122 Month_bl                  float64       \n",
      " 123 Month                     int64         \n",
      " 124 M                         int64         \n",
      " 125 update_stamp              object        \n",
      " 126 TEMPQC                    object        \n",
      " 127 TAU_INNO                  float64       \n",
      " 128 ABETA_INNO                float64       \n",
      " 129 PTAU_INNO                 float64       \n",
      " 130 _merge                    category      \n",
      "dtypes: category(1), datetime64[ns](2), float64(96), int64(5), object(27)\n",
      "memory usage: 831.8+ KB\n"
     ]
    }
   ],
   "source": [
    " df_bothdata.info(max)\n",
    "# df_bothdata.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Remove unneeded columns\n",
    "After the merge, how many columns are there? There should be way more columns than what are needed for the event based model. So we can get rid of unwanted columns that we don't need for the replication. You should have:\n",
    "* 14 feature columns from the list in Step 1\n",
    "* Additional columns that should be include, such as:\n",
    "    * subject identifiers (IDs, visit codes, exam dates, site, protocols)\n",
    "    * demographics (Age, Gender)\n",
    "    * diagnoses\n",
    "    * _APOE_ genetic status\n",
    "    * intracranial volume, to serve as a proxy for head size.\n",
    "    * image quality control (QC) variables (such as `TEMPQC`,`REGRATING`)\n",
    "    * anything else you find relevant. I chose to keep 49 columns, but you may have a few more or a few less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #THESE ARE THE VALUES WE NEED BASED ON THE LIST IN STEP 1\n",
    "\n",
    "# 117  TAU_INNO                  float64\n",
    "#  118  ABETA_INNO                float64\n",
    "#  119  PTAU_INNO                 float64\n",
    " \n",
    "#   55   WholeBrain                float64\n",
    "#  53   Ventricles                float64\n",
    "#   56   Entorhinal                float64\n",
    "#  54   Hippocampus               float64\n",
    "#   58   MidTemp                   float64\n",
    "#  57   Fusiform                  float64\n",
    "#  5   ANN_BBSI    8421 non-null   float64       \n",
    "#  10  ANN_HBSI    4661 non-null   float64       \n",
    "\n",
    "# 26   MMSE                      float64\n",
    "#  24   ADAS13                    float64\n",
    "\n",
    "#  27   RAVLT_immediate           float64\n",
    "#  28   RAVLT_learning            float64\n",
    "#  29   RAVLT_forgetting          float64\n",
    "#  30   RAVLT_perc_forgetting     float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EXAMDATE_old</th>\n",
       "      <th>EXAMDATE_new</th>\n",
       "      <th>VISCODE_old</th>\n",
       "      <th>VISCODE_new</th>\n",
       "      <th>VISCODE2</th>\n",
       "      <th>TEMPQC</th>\n",
       "      <th>QC_PASS</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>...</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>ANN_BBSI</th>\n",
       "      <th>ANN_HBSI</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>RAVLT_immediate</th>\n",
       "      <th>RAVLT_learning</th>\n",
       "      <th>RAVLT_forgetting</th>\n",
       "      <th>RAVLT_perc_forgetting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>74.3</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2005-08-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>27936.0</td>\n",
       "      <td>16559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.67</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.54550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>81.3</td>\n",
       "      <td>2006-09-12</td>\n",
       "      <td>2005-12-09</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>18422.0</td>\n",
       "      <td>15506.0</td>\n",
       "      <td>19.090141</td>\n",
       "      <td>0.229140</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>67.5</td>\n",
       "      <td>2006-11-28</td>\n",
       "      <td>2005-08-11</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>...</td>\n",
       "      <td>19615.0</td>\n",
       "      <td>19036.0</td>\n",
       "      <td>6.027470</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.33</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.36360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>73.7</td>\n",
       "      <td>2006-09-05</td>\n",
       "      <td>2005-07-09</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>21614.0</td>\n",
       "      <td>24788.0</td>\n",
       "      <td>14.563351</td>\n",
       "      <td>0.056883</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.67</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.44440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>80.4</td>\n",
       "      <td>2006-11-28</td>\n",
       "      <td>2005-11-29</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>...</td>\n",
       "      <td>17802.0</td>\n",
       "      <td>17963.0</td>\n",
       "      <td>-2.380889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.67</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.33330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>75.4</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2005-06-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>15374.0</td>\n",
       "      <td>12063.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.33</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>84.5</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2005-09-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>20076.0</td>\n",
       "      <td>14043.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>73.9</td>\n",
       "      <td>2006-11-09</td>\n",
       "      <td>2005-10-11</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>19741.0</td>\n",
       "      <td>16761.0</td>\n",
       "      <td>16.597478</td>\n",
       "      <td>0.269590</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.33</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>78.5</td>\n",
       "      <td>2006-11-28</td>\n",
       "      <td>2005-04-11</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>17798.0</td>\n",
       "      <td>13779.0</td>\n",
       "      <td>1.803046</td>\n",
       "      <td>0.081444</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.33</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.36360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2006-10-17</td>\n",
       "      <td>2005-10-18</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>17273.0</td>\n",
       "      <td>14953.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>65.4</td>\n",
       "      <td>2006-10-10</td>\n",
       "      <td>2005-10-13</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>17596.0</td>\n",
       "      <td>15931.0</td>\n",
       "      <td>4.932808</td>\n",
       "      <td>-0.031926</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>73.1</td>\n",
       "      <td>2006-12-08</td>\n",
       "      <td>2005-11-23</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>16790.0</td>\n",
       "      <td>16497.0</td>\n",
       "      <td>5.724558</td>\n",
       "      <td>0.100260</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.07690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>72.6</td>\n",
       "      <td>2006-11-02</td>\n",
       "      <td>2005-10-24</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>17689.0</td>\n",
       "      <td>18033.0</td>\n",
       "      <td>1.302851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.14286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>63.2</td>\n",
       "      <td>2006-10-19</td>\n",
       "      <td>2005-10-19</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>16845.0</td>\n",
       "      <td>16107.0</td>\n",
       "      <td>-0.144537</td>\n",
       "      <td>-0.008600</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.67</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>71.7</td>\n",
       "      <td>2006-11-21</td>\n",
       "      <td>2005-08-11</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>18030.0</td>\n",
       "      <td>0.801468</td>\n",
       "      <td>0.208890</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>63.63640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29</td>\n",
       "      <td>64.1</td>\n",
       "      <td>2006-11-14</td>\n",
       "      <td>2005-10-31</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>21452.0</td>\n",
       "      <td>15331.0</td>\n",
       "      <td>24.878506</td>\n",
       "      <td>0.094080</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.33</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2006-10-12</td>\n",
       "      <td>2005-10-20</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>...</td>\n",
       "      <td>19953.0</td>\n",
       "      <td>17191.0</td>\n",
       "      <td>6.684971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.90910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31</td>\n",
       "      <td>77.7</td>\n",
       "      <td>2006-10-30</td>\n",
       "      <td>2005-10-24</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>20044.0</td>\n",
       "      <td>13595.0</td>\n",
       "      <td>-2.376509</td>\n",
       "      <td>0.031001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.28570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>83.3</td>\n",
       "      <td>2006-12-14</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>...</td>\n",
       "      <td>18239.0</td>\n",
       "      <td>17446.0</td>\n",
       "      <td>13.286795</td>\n",
       "      <td>0.273750</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25.67</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>35</td>\n",
       "      <td>76.9</td>\n",
       "      <td>2006-11-30</td>\n",
       "      <td>2005-08-11</td>\n",
       "      <td>nv</td>\n",
       "      <td>bl</td>\n",
       "      <td>m12</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>...</td>\n",
       "      <td>22232.0</td>\n",
       "      <td>18317.0</td>\n",
       "      <td>9.284187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.22220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RID   AGE EXAMDATE_old EXAMDATE_new VISCODE_old VISCODE_new VISCODE2  \\\n",
       "0     2  74.3          NaT   2005-08-09         NaN          bl      NaN   \n",
       "1     3  81.3   2006-09-12   2005-12-09          nv          bl      m12   \n",
       "2     4  67.5   2006-11-28   2005-08-11          nv          bl      m12   \n",
       "3     5  73.7   2006-09-05   2005-07-09          nv          bl      m12   \n",
       "4     6  80.4   2006-11-28   2005-11-29          nv          bl      m12   \n",
       "5     7  75.4          NaT   2005-06-10         NaN          bl      NaN   \n",
       "6     8  84.5          NaT   2005-09-19         NaN          bl      NaN   \n",
       "7    10  73.9   2006-11-09   2005-10-11          nv          bl      m12   \n",
       "8    14  78.5   2006-11-28   2005-04-11          nv          bl      m12   \n",
       "9    15  80.8   2006-10-17   2005-10-18          nv          bl      m12   \n",
       "10   16  65.4   2006-10-10   2005-10-13          nv          bl      m12   \n",
       "11   19  73.1   2006-12-08   2005-11-23          nv          bl      m12   \n",
       "12   21  72.6   2006-11-02   2005-10-24          nv          bl      m12   \n",
       "13   22  63.2   2006-10-19   2005-10-19          nv          bl      m12   \n",
       "14   23  71.7   2006-11-21   2005-08-11          nv          bl      m12   \n",
       "15   29  64.1   2006-11-14   2005-10-31          nv          bl      m12   \n",
       "16   30  80.0   2006-10-12   2005-10-20          nv          bl      m12   \n",
       "17   31  77.7   2006-10-30   2005-10-24          nv          bl      m12   \n",
       "18   33  83.3   2006-12-14   2005-09-12          nv          bl      m12   \n",
       "19   35  76.9   2006-11-30   2005-08-11          nv          bl      m12   \n",
       "\n",
       "   TEMPQC  QC_PASS DX_bl  ...  MidTemp Fusiform   ANN_BBSI  ANN_HBSI  MMSE  \\\n",
       "0    Pass      NaN    CN  ...  27936.0  16559.0        NaN       NaN  28.0   \n",
       "1    Pass      1.0    AD  ...  18422.0  15506.0  19.090141  0.229140  20.0   \n",
       "2    Pass      1.0  LMCI  ...  19615.0  19036.0   6.027470  0.020969  27.0   \n",
       "3    Pass      1.0    CN  ...  21614.0  24788.0  14.563351  0.056883  29.0   \n",
       "4    Pass      1.0  LMCI  ...  17802.0  17963.0  -2.380889       NaN  25.0   \n",
       "5    Pass      NaN    AD  ...  15374.0  12063.0        NaN       NaN  20.0   \n",
       "6    Pass      NaN    CN  ...  20076.0  14043.0        NaN       NaN  28.0   \n",
       "7    Pass      1.0    AD  ...  19741.0  16761.0  16.597478  0.269590  24.0   \n",
       "8    Pass      1.0    CN  ...  17798.0  13779.0   1.803046  0.081444  29.0   \n",
       "9    Pass      1.0    CN  ...  17273.0  14953.0        NaN       NaN  29.0   \n",
       "10   Pass      1.0    CN  ...  17596.0  15931.0   4.932808 -0.031926  28.0   \n",
       "11   Pass      1.0    CN  ...  16790.0  16497.0   5.724558  0.100260  29.0   \n",
       "12   Pass      1.0    CN  ...  17689.0  18033.0   1.302851       NaN  30.0   \n",
       "13   Pass      1.0    CN  ...  16845.0  16107.0  -0.144537 -0.008600  29.0   \n",
       "14   Pass      1.0    CN  ...  19500.0  18030.0   0.801468  0.208890  26.0   \n",
       "15   Pass      1.0    AD  ...  21452.0  15331.0  24.878506  0.094080  21.0   \n",
       "16   Fail      1.0  LMCI  ...  19953.0  17191.0   6.684971       NaN  29.0   \n",
       "17   Pass      1.0    CN  ...  20044.0  13595.0  -2.376509  0.031001  30.0   \n",
       "18   Fail      1.0  LMCI  ...  18239.0  17446.0  13.286795  0.273750  29.0   \n",
       "19   Pass      1.0    CN  ...  22232.0  18317.0   9.284187       NaN  30.0   \n",
       "\n",
       "   ADAS13  RAVLT_immediate  RAVLT_learning  RAVLT_forgetting  \\\n",
       "0   18.67             44.0             4.0               6.0   \n",
       "1   31.00             22.0             1.0               4.0   \n",
       "2   21.33             37.0             7.0               4.0   \n",
       "3   14.67             37.0             4.0               4.0   \n",
       "4   25.67             30.0             1.0               5.0   \n",
       "5   40.33             17.0             2.0               3.0   \n",
       "6    7.00             51.0             7.0               3.0   \n",
       "7   24.33             20.0             2.0               5.0   \n",
       "8    8.33             45.0             6.0               4.0   \n",
       "9    9.00             50.0             5.0               3.0   \n",
       "10  14.33             40.0             8.0               6.0   \n",
       "11   4.00             54.0             6.0               3.0   \n",
       "12   9.67             53.0             8.0               1.0   \n",
       "13  13.67             29.0             5.0               2.0   \n",
       "14   8.00             40.0             7.0               7.0   \n",
       "15  34.33             15.0             1.0               4.0   \n",
       "16  22.00             36.0             6.0              10.0   \n",
       "17   1.67             63.0             7.0               2.0   \n",
       "18  25.67             21.0             4.0               6.0   \n",
       "19   9.00             42.0             3.0               2.0   \n",
       "\n",
       "   RAVLT_perc_forgetting  \n",
       "0               54.54550  \n",
       "1              100.00000  \n",
       "2               36.36360  \n",
       "3               44.44440  \n",
       "4               83.33330  \n",
       "5               75.00000  \n",
       "6               25.00000  \n",
       "7              100.00000  \n",
       "8               36.36360  \n",
       "9               25.00000  \n",
       "10              50.00000  \n",
       "11              23.07690  \n",
       "12               7.14286  \n",
       "13              25.00000  \n",
       "14              63.63640  \n",
       "15             100.00000  \n",
       "16              90.90910  \n",
       "17              14.28570  \n",
       "18             100.00000  \n",
       "19              22.22220  \n",
       "\n",
       "[20 rows x 41 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer to Step 4\n",
    "# Below put your code that will remove \n",
    "# unnecessary columns from the data frame.\n",
    "\n",
    "select = ['RID', 'AGE', 'EXAMDATE_old', 'EXAMDATE_new', 'VISCODE_old', 'VISCODE_new', 'VISCODE2', 'TEMPQC', 'QC_PASS', 'DX_bl', 'APOE4', 'MRSEQUENCE', 'PROTOCOL', 'COLPROT', 'ORIGPROT', 'PTID', 'SITE', 'REGRATING', 'ICV', 'PTGENDER', 'PTEDUCAT', 'PTETHCAT', 'PTRACCAT', 'PTMARRY', 'TAU_INNO', 'ABETA_INNO', 'PTAU_INNO', 'WholeBrain', 'Ventricles', 'Entorhinal', 'Hippocampus', 'MidTemp', 'Fusiform', 'ANN_BBSI', 'ANN_HBSI', 'MMSE', 'ADAS13', 'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'RAVLT_perc_forgetting']\n",
    "df_both_clean = df_bothdata.loc[:, select]\n",
    "df_both_clean.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Identify complete case data\n",
    "The Event Based Model requires all features to be present for an observation to be included. Please remove any rows where one of the features that you plan to put in the EBM has missing data.\n",
    "\n",
    "Please remove any data which failed QC check. The key column to check is `TEMPQC`.\n",
    "\n",
    "Answer a few questions:\n",
    "* For each variable, how many subjects had missing data? \n",
    "* How many subjects remain? \n",
    "* How do the subjects break down across diagnosis?\n",
    "* Within diagnosis, how do they breakdown in terms of sex, age, APOE status?\n",
    "* How do these numbers compare to the paper? \n",
    "\n",
    "This should be your final data set, which should consist of 283 participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEMPQC\n",
       "Pass    665\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer to Step 5\n",
    "# Below put your code to remove missing data\n",
    "# and answer the descriptive statsitics queries\n",
    "# around the final data set\n",
    "\n",
    "#remove failed QC\n",
    "df_both_clean.value_counts('TEMPQC')\n",
    "df_both_qc = df_both_clean[df_both_clean['TEMPQC'] != 'Fail']\n",
    "df_both_qc.value_counts('TEMPQC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RID                        0\n",
       "AGE                        0\n",
       "EXAMDATE_old             108\n",
       "EXAMDATE_new               0\n",
       "VISCODE_old              108\n",
       "VISCODE_new                0\n",
       "VISCODE2                 108\n",
       "TEMPQC                     0\n",
       "QC_PASS                  108\n",
       "DX_bl                      0\n",
       "APOE4                      0\n",
       "MRSEQUENCE               108\n",
       "PROTOCOL                 108\n",
       "COLPROT                    0\n",
       "ORIGPROT                   0\n",
       "PTID                       0\n",
       "SITE                       0\n",
       "REGRATING                108\n",
       "ICV                        0\n",
       "PTGENDER                   0\n",
       "PTEDUCAT                   0\n",
       "PTETHCAT                   0\n",
       "PTRACCAT                   0\n",
       "PTMARRY                    0\n",
       "TAU_INNO                 380\n",
       "ABETA_INNO               380\n",
       "PTAU_INNO                380\n",
       "WholeBrain                 0\n",
       "Ventricles                 4\n",
       "Entorhinal                 0\n",
       "Hippocampus                0\n",
       "MidTemp                    0\n",
       "Fusiform                   0\n",
       "ANN_BBSI                 148\n",
       "ANN_HBSI                 380\n",
       "MMSE                       0\n",
       "ADAS13                     5\n",
       "RAVLT_immediate            2\n",
       "RAVLT_learning             2\n",
       "RAVLT_forgetting           2\n",
       "RAVLT_perc_forgetting      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many subjects with missing data\n",
    "df_both_qc.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 282 entries, 1 to 812\n",
      "Data columns (total 41 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   RID                    282 non-null    int64         \n",
      " 1   AGE                    282 non-null    float64       \n",
      " 2   EXAMDATE_old           282 non-null    datetime64[ns]\n",
      " 3   EXAMDATE_new           282 non-null    datetime64[ns]\n",
      " 4   VISCODE_old            282 non-null    object        \n",
      " 5   VISCODE_new            282 non-null    object        \n",
      " 6   VISCODE2               282 non-null    object        \n",
      " 7   TEMPQC                 282 non-null    object        \n",
      " 8   QC_PASS                282 non-null    float64       \n",
      " 9   DX_bl                  282 non-null    object        \n",
      " 10  APOE4                  282 non-null    float64       \n",
      " 11  MRSEQUENCE             282 non-null    object        \n",
      " 12  PROTOCOL               282 non-null    object        \n",
      " 13  COLPROT                282 non-null    object        \n",
      " 14  ORIGPROT               282 non-null    object        \n",
      " 15  PTID                   282 non-null    object        \n",
      " 16  SITE                   282 non-null    int64         \n",
      " 17  REGRATING              282 non-null    float64       \n",
      " 18  ICV                    282 non-null    float64       \n",
      " 19  PTGENDER               282 non-null    object        \n",
      " 20  PTEDUCAT               282 non-null    int64         \n",
      " 21  PTETHCAT               282 non-null    object        \n",
      " 22  PTRACCAT               282 non-null    object        \n",
      " 23  PTMARRY                282 non-null    object        \n",
      " 24  TAU_INNO               282 non-null    float64       \n",
      " 25  ABETA_INNO             282 non-null    float64       \n",
      " 26  PTAU_INNO              282 non-null    float64       \n",
      " 27  WholeBrain             282 non-null    float64       \n",
      " 28  Ventricles             282 non-null    float64       \n",
      " 29  Entorhinal             282 non-null    float64       \n",
      " 30  Hippocampus            282 non-null    float64       \n",
      " 31  MidTemp                282 non-null    float64       \n",
      " 32  Fusiform               282 non-null    float64       \n",
      " 33  ANN_BBSI               282 non-null    float64       \n",
      " 34  ANN_HBSI               282 non-null    float64       \n",
      " 35  MMSE                   282 non-null    float64       \n",
      " 36  ADAS13                 282 non-null    float64       \n",
      " 37  RAVLT_immediate        282 non-null    float64       \n",
      " 38  RAVLT_learning         282 non-null    float64       \n",
      " 39  RAVLT_forgetting       282 non-null    float64       \n",
      " 40  RAVLT_perc_forgetting  282 non-null    float64       \n",
      "dtypes: datetime64[ns](2), float64(22), int64(3), object(14)\n",
      "memory usage: 92.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#drop rows with NaN values\n",
    "df_both_complete = df_both_qc.dropna()\n",
    "df_both_complete.shape\n",
    "df_both_complete.head(20)\n",
    "df_both_complete.info()\n",
    "\n",
    "\n",
    "#DX breakdown amongst remaining patients\n",
    "# df_both_complete['DX_bl'].value_counts()\n",
    "\n",
    "#STudy had 129 LMCI, 92 CN, and 64 AD, I have 282 patients so I'm missing one somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "data_root = \"/Users/catriona/src/TeamCoders/EBM/TeamCoders_Event_Based_Model/Data_Cleaning_And_Wrangling/data/\"\n",
    "df_both_complete.to_csv(os.path.join(data_root,\"ebm_mine.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_both_complete_dx = df_both_complete.groupby('DX_bl')\n",
    "df_LMCI = df_both_complete_dx.get_group('LMCI')\n",
    "df_CN = df_both_complete_dx.get_group('CN')\n",
    "df_AD = df_both_complete_dx.get_group('AD')\n",
    "\n",
    "\n",
    "#Counts of age, gender, APOE within each DX group\n",
    "df_age_lmci = df_LMCI.value_counts('AGE')\n",
    "df_age_cn = df_CN.value_counts('AGE')\n",
    "df_age_ad = df_AD.value_counts('AGE')\n",
    "\n",
    "print(f\"LMCI: {df_age_lmci}, \\n CN: {df_age_cn}, \\n AD: {df_age_ad} \\n \\n\")\n",
    "\n",
    "df_gender_lmci = df_LMCI.value_counts('PTGENDER')\n",
    "df_gender_cn = df_CN.value_counts('PTGENDER')\n",
    "df_gender_ad = df_AD.value_counts('PTGENDER')\n",
    "\n",
    "print(f\"LMCI: {df_gender_lmci}, \\n CN: {df_gender_cn}, \\n AD: {df_gender_ad} \\n \\n\")\n",
    "\n",
    "df_APOE_lmci = df_LMCI.value_counts('APOE4')\n",
    "df_APOE_cn = df_CN.value_counts('APOE4')\n",
    "df_APOE_ad = df_AD.value_counts('APOE4')\n",
    "\n",
    "print(f\"LMCI: {df_APOE_lmci}, \\n CN: {df_APOE_cn}, \\n AD: {df_APOE_ad} \\n \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Data review\n",
    "We have looked at the final data set at a group level, but let's actually visualise the data. For the various features that are to be included in the EBM, create some plots of your choice to look at how these values differ between the cognitively normal individuals and those showing evidence of cognitive impairment. You can break this latter group into mild cognitive impairment and Alzheimer's disease if you wish. You can also look at how this varies with _APOE_ status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer to Step 6\n",
    "\n",
    "# 117  TAU_INNO                  float64\n",
    "#  118  ABETA_INNO                float64\n",
    "#  119  PTAU_INNO                 float64\n",
    " \n",
    "#   55   WholeBrain                float64\n",
    "#  53   Ventricles                float64\n",
    "#   56   Entorhinal                float64\n",
    "#  54   Hippocampus               float64\n",
    "#   58   MidTemp                   float64\n",
    "#  57   Fusiform                  float64\n",
    "#  5   ANN_BBSI    8421 non-null   float64       \n",
    "#  10  ANN_HBSI    4661 non-null   float64       \n",
    "\n",
    "# 26   MMSE                      float64\n",
    "#  24   ADAS13                    float64\n",
    "\n",
    "#  27   RAVLT_immediate           float64\n",
    "#  28   RAVLT_learning            float64\n",
    "#  29   RAVLT_forgetting          float64\n",
    "#  30   RAVLT_perc_forgetting     float64\n",
    "\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "#Plot each tau in each group\n",
    "\n",
    "fig=plt.figure(figsize=(12.0, 8.0))\n",
    "# Plot one Cases versus population for males\n",
    "ax1= fig.add_subplot(1,3,1)\n",
    "# First plot - across all countries and yearsHere we plot bar using the plt.bar() function and it is set at the ax1 which is axes1 subplot variable\n",
    "ax1.set_title('TAU_INNO by ventricular volume') \n",
    "ax1.plot(df_LMCI['Ventricles'],df_LMCI['TAU_INNO'],'.')\n",
    "ax1.plot(df_AD['Ventricles'],df_AD['TAU_INNO'],'.')\n",
    "ax1.plot(df_CN['Ventricles'],df_CN['TAU_INNO'],'x')\n",
    "\n",
    "ax1= fig.add_subplot(1,3,2)\n",
    "# Second plot - across all countries and yearsHere we plot bar using the plt.bar() function and it is set at the ax1 which is axes1 subplot variable\n",
    "ax1.set_title('ABETA_INNO by ventricular volume') \n",
    "ax1.plot(df_LMCI['Ventricles'],df_LMCI['ABETA_INNO'],'.')\n",
    "ax1.plot(df_AD['Ventricles'],df_AD['ABETA_INNO'],'.')\n",
    "ax1.plot(df_CN['Ventricles'],df_CN['ABETA_INNO'],'x')\n",
    "\n",
    "ax1= fig.add_subplot(1,3,3)\n",
    "# Second plot - across all countries and yearsHere we plot bar using the plt.bar() function and it is set at the ax1 which is axes1 subplot variable\n",
    "ax1.set_title('PTAU_INNO by ventricular volume') \n",
    "ax1.plot(df_LMCI['Ventricles'],df_LMCI['PTAU_INNO'],'.')\n",
    "ax1.plot(df_AD['Ventricles'],df_AD['PTAU_INNO'],'.')\n",
    "ax1.plot(df_CN['Ventricles'],df_CN['PTAU_INNO'],'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract each APOE status\n",
    "df_both_complete['APOE4'].value_counts()\n",
    "df_apoe_0 = df_both_complete[df_both_complete['APOE4'] == 0.0]\n",
    "df_apoe_1 = df_both_complete[df_both_complete['APOE4'] == 1.0]\n",
    "df_apoe_2 = df_both_complete[df_both_complete['APOE4'] == 2.0]\n",
    "\n",
    "#groupby is good for stats over a group, can convert numeric values into different data type (enumerate?)\n",
    "#[13:24] Cash, Dave    df_adni = df_adni[df_adni['VISCODE']=='bl']\n",
    "#can also use loc function\n",
    "# df_adni = df_adni.loc[:,'VISCODE'=='bl']\n",
    "\n",
    "# Scatter plot for df1\n",
    "plt.scatter(df_apoe_0['ANN_HBSI'], df_apoe_0['ABETA_INNO'], label='APOE 0')\n",
    "\n",
    "# Scatter plot for df2\n",
    "plt.scatter(df_apoe_1['ANN_HBSI'], df_apoe_1['ABETA_INNO'], label='APOE 1')\n",
    "\n",
    "# Scatter plot for df3\n",
    "plt.scatter(df_apoe_2['ANN_HBSI'], df_apoe_2['ABETA_INNO'], label='APOE 2')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Month 12 Annualised Hippocampal BSI')\n",
    "plt.ylabel('Amyloid Beta 1-42')\n",
    "plt.title('Amyloid Beta 1-42 against Hippocampal BSI')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ca3c52c2c6a741687ac119195f853fd55cbbadb57e664fb666b72dd14734ec5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
